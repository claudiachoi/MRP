{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import asarray, savez_compressed, load\n",
    "from collections import Counter\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import resnet50  \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load saved satellite imagery data\n",
    "def load_saved_dataset(file):\n",
    "    data = load(file)\n",
    "    X, y = data['arr_0'], data['arr_1']\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.20)\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    return trainX, trainY, testX, testY\n",
    "  \n",
    "#function to evaluate model    \n",
    "def eval(testY, predY):\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(testY, predY)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(testY, predY, average='macro')\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(testY, predY, average='macro')\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(testY, predY, average='macro')\n",
    "    print('F1 score: %f' % f1)\n",
    "    cm = confusion_matrix(testY, predY)\n",
    "    print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pedestrian Accidents - First Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46283, 128, 128, 3) (46283,) (11571, 128, 128, 3) (11571,)\n",
      "Counter({0: 45069, 1: 863, 2: 300, 3: 51}) Counter({0: 11244, 1: 226, 2: 91, 3: 10})\n",
      "Mean:  11571\n",
      "After SMOTE:  (79782, 49152) (79782,) Counter({0: 45069, 1: 11571, 2: 11571, 3: 11571})\n",
      "After undersampling Majority:  (34713, 49152) (34713,) (45069, 49152)\n",
      "Final Class Counter:  Counter({0: 11571, 1: 11571, 2: 11571, 3: 11571})\n",
      "Final training dataset:  (46284, 128, 128, 3) (46284, 4)\n",
      "Final validation dataset:  (11571, 128, 128, 3) (11571, 4)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainX, trainY, testX, testY = load_saved_dataset('ped_acc.npz')\n",
    "print(Counter(trainY), Counter(testY))\n",
    "#find average number of instances\n",
    "m = round(sum(Counter(trainY).values())/4)\n",
    "print('Mean: ', m)\n",
    "#implement SMOTE on minority classes\n",
    "trainX = trainX.reshape(trainX.shape[0], -1)\n",
    "sm = SMOTE({1:m, 2:m, 3:m})\n",
    "X_sm, Y_sm = sm.fit_sample(trainX, trainY)\n",
    "print('After SMOTE: ', X_sm.shape, Y_sm.shape, Counter(Y_sm))\n",
    "#split out majority set from dataset\n",
    "ds_maj = []\n",
    "X_tmp = []\n",
    "Y_tmp = []\n",
    "for i in range(len(X_sm)):\n",
    "    target = Y_sm[i]\n",
    "    var = X_sm[i]\n",
    "    if target == 0:\n",
    "        ds_maj.append(var)\n",
    "    if target == 1:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(1)\n",
    "    if target == 2:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(2)\n",
    "    if target == 3:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(3)\n",
    "\n",
    "X_tmp = np.asarray(X_tmp)\n",
    "Y_tmp = np.asarray(Y_tmp)\n",
    "ds_maj = np.asarray(ds_maj)\n",
    "print('After undersampling Majority: ', X_tmp.shape, Y_tmp.shape, ds_maj.shape)\n",
    "#undersample majority set to m number of instances\n",
    "ds_maj = shuffle(ds_maj, n_samples=m)\n",
    "#generate target set of 0's for undersampled majority set\n",
    "ds_maj_y = np.repeat(0, len(ds_maj))\n",
    "#combine datasets\n",
    "X1_tmp = np.concatenate([X_tmp, ds_maj])\n",
    "Y1_tmp = np.concatenate([Y_tmp, ds_maj_y])\n",
    "#shuffle combined dataset\n",
    "X_sm, Y_sm = shuffle(X1_tmp, Y1_tmp, random_state=1)\n",
    "print('Final Class Counter: ', Counter(Y_sm))\n",
    "#prepare data for training\n",
    "X_sm = X_sm.reshape(X_sm.shape[0], 128, 128, 3)\n",
    "Y_sm = to_categorical(Y_sm)\n",
    "testY = to_categorical(testY)\n",
    "print('Final training dataset: ', X_sm.shape, Y_sm.shape)\n",
    "print('Final validation dataset: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 14:49:37.451262 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 14:49:37.478320 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 14:49:37.490186 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0804 14:49:37.517039 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0804 14:49:37.517740 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 14:49:41.340316 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0804 14:49:41.410105 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0804 14:49:50.145723 139900605351680 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 14:49:50.189503 139900605351680 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 14:49:50.334825 139900605351680 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46284 samples, validate on 11571 samples\n",
      "Epoch 1/25\n",
      "46284/46284 [==============================] - 224s 5ms/step - loss: 0.4161 - acc: 0.8332 - val_loss: 0.1344 - val_acc: 0.9665\n",
      "Epoch 2/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0667 - acc: 0.9770 - val_loss: 0.1718 - val_acc: 0.9548\n",
      "Epoch 3/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.2184 - val_acc: 0.9488\n",
      "Epoch 4/25\n",
      "46284/46284 [==============================] - 202s 4ms/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.2523 - val_acc: 0.9627\n",
      "Epoch 5/25\n",
      "46284/46284 [==============================] - 202s 4ms/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.2712 - val_acc: 0.9431\n",
      "Epoch 6/25\n",
      "46284/46284 [==============================] - 202s 4ms/step - loss: 0.0190 - acc: 0.9936 - val_loss: 0.2566 - val_acc: 0.9480\n",
      "Epoch 7/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.2264 - val_acc: 0.9608\n",
      "Epoch 8/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.2955 - val_acc: 0.9324\n",
      "Epoch 9/25\n",
      "46284/46284 [==============================] - 202s 4ms/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.2628 - val_acc: 0.9534\n",
      "Epoch 10/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.5021 - val_acc: 0.8837\n",
      "Epoch 11/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.4618 - val_acc: 0.8775\n",
      "Epoch 12/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.2877 - val_acc: 0.9439\n",
      "Epoch 13/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.2524 - val_acc: 0.9508\n",
      "Epoch 14/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.2978 - val_acc: 0.9632\n",
      "Epoch 15/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.3393 - val_acc: 0.9655\n",
      "Epoch 16/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0095 - acc: 0.9969 - val_loss: 0.2880 - val_acc: 0.9646\n",
      "Epoch 17/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.2846 - val_acc: 0.9525\n",
      "Epoch 18/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.2938 - val_acc: 0.9471\n",
      "Epoch 19/25\n",
      "46284/46284 [==============================] - 202s 4ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.2814 - val_acc: 0.9593\n",
      "Epoch 20/25\n",
      "46284/46284 [==============================] - 202s 4ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.3066 - val_acc: 0.9526\n",
      "Epoch 21/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0073 - acc: 0.9982 - val_loss: 0.2495 - val_acc: 0.9531\n",
      "Epoch 22/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.3095 - val_acc: 0.9485\n",
      "Epoch 23/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.2742 - val_acc: 0.9507\n",
      "Epoch 24/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.2793 - val_acc: 0.9652\n",
      "Epoch 25/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.3106 - val_acc: 0.9590\n"
     ]
    }
   ],
   "source": [
    "#train first split\n",
    "base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (128,128,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model_dssm1 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_dssm1.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history1 = model_dssm1.fit(X_sm, Y_sm, validation_data=(testX, testY), epochs= 25, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.959036\n",
      "Precision: 0.379923\n",
      "Recall: 0.311289\n",
      "F1 score: 0.326160\n",
      "Confusion Matrix:\n",
      " [[11061   169    13     1]\n",
      " [  188    34     4     0]\n",
      " [   73    16     1     1]\n",
      " [    8     1     0     1]]\n"
     ]
    }
   ],
   "source": [
    "#model predictions\n",
    "predictions = model_dssm1.predict(testX)\n",
    "predY = np.argmax(predictions, axis=1)\n",
    "testY = np.argmax(testY, axis=1)\n",
    "#Results #1\n",
    "eval(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pedestrian Accidents - Second Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46283, 128, 128, 3) (46283,) (11571, 128, 128, 3) (11571,)\n",
      "Counter({0: 45060, 1: 857, 2: 316, 3: 50}) Counter({0: 11253, 1: 232, 2: 75, 3: 11})\n",
      "Mean:  11571\n",
      "After SMOTE:  (79773, 49152) (79773,) Counter({0: 45060, 1: 11571, 2: 11571, 3: 11571})\n",
      "After undersampling Majority:  (34713, 49152) (34713,) (45060, 49152)\n",
      "Final Class Counter:  Counter({0: 11571, 1: 11571, 2: 11571, 3: 11571})\n",
      "Final training dataset:  (46284, 128, 128, 3) (46284, 4)\n",
      "Final validation dataset:  (11571, 128, 128, 3) (11571, 4)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainX, trainY, testX, testY = load_saved_dataset('ped_acc.npz')\n",
    "print(Counter(trainY), Counter(testY))\n",
    "#find average number of instances\n",
    "m = round(sum(Counter(trainY).values())/4)\n",
    "print('Mean: ', m)\n",
    "#implement SMOTE on minority classes\n",
    "trainX = trainX.reshape(trainX.shape[0], -1)\n",
    "sm = SMOTE({1:m, 2:m, 3:m})\n",
    "X_sm, Y_sm = sm.fit_sample(trainX, trainY)\n",
    "print('After SMOTE: ', X_sm.shape, Y_sm.shape, Counter(Y_sm))\n",
    "#split out majority set from dataset\n",
    "ds_maj = []\n",
    "X_tmp = []\n",
    "Y_tmp = []\n",
    "for i in range(len(X_sm)):\n",
    "    target = Y_sm[i]\n",
    "    var = X_sm[i]\n",
    "    if target == 0:\n",
    "        ds_maj.append(var)\n",
    "    if target == 1:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(1)\n",
    "    if target == 2:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(2)\n",
    "    if target == 3:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(3)\n",
    "\n",
    "X_tmp = np.asarray(X_tmp)\n",
    "Y_tmp = np.asarray(Y_tmp)\n",
    "ds_maj = np.asarray(ds_maj)\n",
    "print('After undersampling Majority: ', X_tmp.shape, Y_tmp.shape, ds_maj.shape)\n",
    "#undersample majority set to m number of instances\n",
    "ds_maj = shuffle(ds_maj, n_samples=m)\n",
    "#generate target set of 0's for undersampled majority set\n",
    "ds_maj_y = np.repeat(0, len(ds_maj))\n",
    "#combine datasets\n",
    "X1_tmp = np.concatenate([X_tmp, ds_maj])\n",
    "Y1_tmp = np.concatenate([Y_tmp, ds_maj_y])\n",
    "#shuffle combined dataset\n",
    "X_sm, Y_sm = shuffle(X1_tmp, Y1_tmp, random_state=1)\n",
    "print('Final Class Counter: ', Counter(Y_sm))\n",
    "#prepare data for training\n",
    "X_sm = X_sm.reshape(X_sm.shape[0], 128, 128, 3)\n",
    "Y_sm = to_categorical(Y_sm)\n",
    "testY = to_categorical(testY)\n",
    "print('Final training dataset: ', X_sm.shape, Y_sm.shape)\n",
    "print('Final validation dataset: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 16:28:25.952041 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 16:28:25.967650 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 16:28:25.972793 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0804 16:28:25.994935 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0804 16:28:25.995633 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 16:28:27.629254 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0804 16:28:27.692338 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0804 16:28:36.573124 140251022423808 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 16:28:36.613466 140251022423808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 16:28:36.740025 140251022423808 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46284 samples, validate on 11571 samples\n",
      "Epoch 1/25\n",
      "46284/46284 [==============================] - 225s 5ms/step - loss: 0.4333 - acc: 0.8229 - val_loss: 0.1564 - val_acc: 0.9544\n",
      "Epoch 2/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0663 - acc: 0.9772 - val_loss: 0.2122 - val_acc: 0.9396\n",
      "Epoch 3/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.2036 - val_acc: 0.9640\n",
      "Epoch 4/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.2031 - val_acc: 0.9582\n",
      "Epoch 5/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0185 - acc: 0.9937 - val_loss: 0.2348 - val_acc: 0.9465\n",
      "Epoch 6/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.2261 - val_acc: 0.9543\n",
      "Epoch 7/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0142 - acc: 0.9959 - val_loss: 0.3082 - val_acc: 0.9394\n",
      "Epoch 8/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0108 - acc: 0.9965 - val_loss: 0.2412 - val_acc: 0.9596\n",
      "Epoch 9/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.2444 - val_acc: 0.9632\n",
      "Epoch 10/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.2638 - val_acc: 0.9545\n",
      "Epoch 11/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.2535 - val_acc: 0.9575\n",
      "Epoch 12/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.2695 - val_acc: 0.9432\n",
      "Epoch 13/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.2715 - val_acc: 0.9392\n",
      "Epoch 14/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.2682 - val_acc: 0.9453\n",
      "Epoch 15/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.2584 - val_acc: 0.9612\n",
      "Epoch 16/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.2618 - val_acc: 0.9585\n",
      "Epoch 17/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.2859 - val_acc: 0.9527\n",
      "Epoch 18/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.2757 - val_acc: 0.9539\n",
      "Epoch 19/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.2973 - val_acc: 0.9474\n",
      "Epoch 20/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.2818 - val_acc: 0.9669\n",
      "Epoch 21/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.2729 - val_acc: 0.9510\n",
      "Epoch 22/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.3813 - val_acc: 0.9299\n",
      "Epoch 23/25\n",
      "46284/46284 [==============================] - 206s 4ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.3061 - val_acc: 0.9621\n",
      "Epoch 24/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.3007 - val_acc: 0.9534\n",
      "Epoch 25/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.3432 - val_acc: 0.9380\n"
     ]
    }
   ],
   "source": [
    "#train second split\n",
    "base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (128,128,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model_dssm2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_dssm2.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history2 = model_dssm2.fit(X_sm, Y_sm, validation_data=(testX, testY), epochs= 25, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.938035\n",
      "Precision: 0.297224\n",
      "Recall: 0.316647\n",
      "F1 score: 0.298686\n",
      "Confusion Matrix:\n",
      " [[10791   435    27     0]\n",
      " [  162    59    11     0]\n",
      " [   52    19     4     0]\n",
      " [    4     7     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudiachoi57/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/claudiachoi57/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#model predictions\n",
    "predictions = model_dssm2.predict(testX)\n",
    "predY = np.argmax(predictions, axis=1)\n",
    "testY = np.argmax(testY, axis=1)\n",
    "#Results #2\n",
    "eval(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pedestrian Accidents - Third Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46283, 128, 128, 3) (46283,) (11571, 128, 128, 3) (11571,)\n",
      "Counter({0: 45030, 1: 896, 2: 305, 3: 52}) Counter({0: 11283, 1: 193, 2: 86, 3: 9})\n",
      "Mean:  11571\n",
      "After SMOTE:  (79743, 49152) (79743,) Counter({0: 45030, 1: 11571, 2: 11571, 3: 11571})\n",
      "After undersampling Majority:  (34713, 49152) (34713,) (45030, 49152)\n",
      "Final Class Counter:  Counter({0: 11571, 1: 11571, 2: 11571, 3: 11571})\n",
      "Final training dataset:  (46284, 128, 128, 3) (46284, 4)\n",
      "Final validation dataset:  (11571, 128, 128, 3) (11571, 4)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainX, trainY, testX, testY = load_saved_dataset('ped_acc.npz')\n",
    "print(Counter(trainY), Counter(testY))\n",
    "#find average number of instances\n",
    "m = round(sum(Counter(trainY).values())/4)\n",
    "print('Mean: ', m)\n",
    "#implement SMOTE on minority classes\n",
    "trainX = trainX.reshape(trainX.shape[0], -1)\n",
    "sm = SMOTE({1:m, 2:m, 3:m})\n",
    "X_sm, Y_sm = sm.fit_sample(trainX, trainY)\n",
    "print('After SMOTE: ', X_sm.shape, Y_sm.shape, Counter(Y_sm))\n",
    "#split out majority set from dataset\n",
    "ds_maj = []\n",
    "X_tmp = []\n",
    "Y_tmp = []\n",
    "for i in range(len(X_sm)):\n",
    "    target = Y_sm[i]\n",
    "    var = X_sm[i]\n",
    "    if target == 0:\n",
    "        ds_maj.append(var)\n",
    "    if target == 1:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(1)\n",
    "    if target == 2:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(2)\n",
    "    if target == 3:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(3)\n",
    "\n",
    "X_tmp = np.asarray(X_tmp)\n",
    "Y_tmp = np.asarray(Y_tmp)\n",
    "ds_maj = np.asarray(ds_maj)\n",
    "print('After undersampling Majority: ', X_tmp.shape, Y_tmp.shape, ds_maj.shape)\n",
    "#undersample majority set to m number of instances\n",
    "ds_maj = shuffle(ds_maj, n_samples=m)\n",
    "#generate target set of 0's for undersampled majority set\n",
    "ds_maj_y = np.repeat(0, len(ds_maj))\n",
    "#combine datasets\n",
    "X1_tmp = np.concatenate([X_tmp, ds_maj])\n",
    "Y1_tmp = np.concatenate([Y_tmp, ds_maj_y])\n",
    "#shuffle combined dataset\n",
    "X_sm, Y_sm = shuffle(X1_tmp, Y1_tmp, random_state=1)\n",
    "print('Final Class Counter: ', Counter(Y_sm))\n",
    "#prepare data for training\n",
    "X_sm = X_sm.reshape(X_sm.shape[0], 128, 128, 3)\n",
    "Y_sm = to_categorical(Y_sm)\n",
    "testY = to_categorical(testY)\n",
    "print('Final training dataset: ', X_sm.shape, Y_sm.shape)\n",
    "print('Final validation dataset: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 19:00:17.020333 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 19:00:17.035673 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 19:00:17.040537 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0804 19:00:17.061901 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0804 19:00:17.062586 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 19:00:18.731277 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0804 19:00:18.796731 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0804 19:00:27.242551 139644722501376 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 19:00:27.284984 139644722501376 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 19:00:27.416432 139644722501376 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46284 samples, validate on 11571 samples\n",
      "Epoch 1/25\n",
      "46284/46284 [==============================] - 227s 5ms/step - loss: 0.4273 - acc: 0.8224 - val_loss: 0.1484 - val_acc: 0.9601\n",
      "Epoch 2/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0661 - acc: 0.9772 - val_loss: 0.1440 - val_acc: 0.9609\n",
      "Epoch 3/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0203 - acc: 0.9939 - val_loss: 0.2086 - val_acc: 0.9414\n",
      "Epoch 4/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.1774 - val_acc: 0.9641\n",
      "Epoch 5/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.2256 - val_acc: 0.9581\n",
      "Epoch 6/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.3329 - val_acc: 0.9233\n",
      "Epoch 7/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0158 - acc: 0.9952 - val_loss: 0.2317 - val_acc: 0.9491\n",
      "Epoch 8/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.2381 - val_acc: 0.9546\n",
      "Epoch 9/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.2254 - val_acc: 0.9702\n",
      "Epoch 10/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.2466 - val_acc: 0.9590\n",
      "Epoch 11/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.2808 - val_acc: 0.9544\n",
      "Epoch 12/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.2680 - val_acc: 0.9575\n",
      "Epoch 13/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.2332 - val_acc: 0.9674\n",
      "Epoch 14/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.2243 - val_acc: 0.9659\n",
      "Epoch 15/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.2511 - val_acc: 0.9647\n",
      "Epoch 16/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.2687 - val_acc: 0.9567\n",
      "Epoch 17/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.2432 - val_acc: 0.9596\n",
      "Epoch 18/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.2574 - val_acc: 0.9565\n",
      "Epoch 19/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.2444 - val_acc: 0.9637\n",
      "Epoch 20/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.2653 - val_acc: 0.9618\n",
      "Epoch 21/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.2378 - val_acc: 0.9652\n",
      "Epoch 22/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.2579 - val_acc: 0.9596\n",
      "Epoch 23/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.2320 - val_acc: 0.9635\n",
      "Epoch 24/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.2755 - val_acc: 0.9499\n",
      "Epoch 25/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.2688 - val_acc: 0.9532\n"
     ]
    }
   ],
   "source": [
    "#train third split\n",
    "base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (128,128,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model_dssm3 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_dssm3.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history3 = model_dssm3.fit(X_sm, Y_sm, validation_data=(testX, testY), epochs= 25, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953159\n",
      "Precision: 0.303816\n",
      "Recall: 0.313624\n",
      "F1 score: 0.306615\n",
      "Confusion Matrix:\n",
      " [[10986   246    51     0]\n",
      " [  145    34    13     1]\n",
      " [   53    24     9     0]\n",
      " [    4     5     0     0]]\n"
     ]
    }
   ],
   "source": [
    "#model predictions\n",
    "predictions = model_dssm3.predict(testX)\n",
    "predY = np.argmax(predictions, axis=1)\n",
    "testY = np.argmax(testY, axis=1)\n",
    "#Results #3\n",
    "eval(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
