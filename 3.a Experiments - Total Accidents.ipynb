{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import asarray, savez_compressed, load\n",
    "from collections import Counter\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import resnet50  \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load saved satellite imagery data\n",
    "def load_saved_dataset(file):\n",
    "    data = load(file)\n",
    "    X, y = data['arr_0'], data['arr_1']\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.20)\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    return trainX, trainY, testX, testY\n",
    "  \n",
    "#function to evaluate model    \n",
    "def eval(testY, predY):\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(testY, predY)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(testY, predY, average='macro')\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(testY, predY, average='macro')\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(testY, predY, average='macro')\n",
    "    print('F1 score: %f' % f1)\n",
    "    cm = confusion_matrix(testY, predY)\n",
    "    print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Road Accidents - First Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46283, 128, 128, 3) (46283,) (11571, 128, 128, 3) (11571,)\n",
      "Counter({0: 43936, 1: 1650, 2: 587, 3: 110}) Counter({0: 11001, 1: 399, 2: 145, 3: 26})\n",
      "Mean:  11571\n",
      "After SMOTE:  (78649, 49152) (78649,) Counter({0: 43936, 1: 11571, 2: 11571, 3: 11571})\n",
      "After undersampling Majority:  (34713, 49152) (34713,) (43936, 49152)\n",
      "Final Class Counter:  Counter({0: 11571, 1: 11571, 2: 11571, 3: 11571})\n",
      "Final training dataset:  (46284, 128, 128, 3) (46284, 4)\n",
      "Final validation dataset:  (11571, 128, 128, 3) (11571, 4)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainX, trainY, testX, testY = load_saved_dataset('total_acc.npz')\n",
    "print(Counter(trainY), Counter(testY))\n",
    "#find average number of instances\n",
    "m = round(sum(Counter(trainY).values())/4)\n",
    "print('Mean: ', m)\n",
    "#implement SMOTE on minority classes\n",
    "trainX = trainX.reshape(trainX.shape[0], -1)\n",
    "sm = SMOTE({1:m, 2:m, 3:m})\n",
    "X_sm, Y_sm = sm.fit_sample(trainX, trainY)\n",
    "print('After SMOTE: ', X_sm.shape, Y_sm.shape, Counter(Y_sm))\n",
    "#split out majority set from dataset\n",
    "ds_maj = []\n",
    "X_tmp = []\n",
    "Y_tmp = []\n",
    "for i in range(len(X_sm)):\n",
    "    target = Y_sm[i]\n",
    "    var = X_sm[i]\n",
    "    if target == 0:\n",
    "        ds_maj.append(var)\n",
    "    if target == 1:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(1)\n",
    "    if target == 2:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(2)\n",
    "    if target == 3:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(3)\n",
    "\n",
    "X_tmp = np.asarray(X_tmp)\n",
    "Y_tmp = np.asarray(Y_tmp)\n",
    "ds_maj = np.asarray(ds_maj)\n",
    "print('After undersampling Majority: ', X_tmp.shape, Y_tmp.shape, ds_maj.shape)\n",
    "#undersample majority set to m number of instances\n",
    "ds_maj = shuffle(ds_maj, n_samples=m)\n",
    "#generate target set of 0's for undersampled majority set\n",
    "ds_maj_y = np.repeat(0, len(ds_maj))\n",
    "#combine datasets\n",
    "X1_tmp = np.concatenate([X_tmp, ds_maj])\n",
    "Y1_tmp = np.concatenate([Y_tmp, ds_maj_y])\n",
    "#shuffle combined dataset\n",
    "X_sm, Y_sm = shuffle(X1_tmp, Y1_tmp, random_state=1)\n",
    "print('Final Class Counter: ', Counter(Y_sm))\n",
    "#prepare data for training\n",
    "X_sm = X_sm.reshape(X_sm.shape[0], 128, 128, 3)\n",
    "Y_sm = to_categorical(Y_sm)\n",
    "testY = to_categorical(testY)\n",
    "print('Final training dataset: ', X_sm.shape, Y_sm.shape)\n",
    "print('Final validation dataset: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 02:00:03.163785 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0805 02:00:03.183815 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 02:00:03.189993 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0805 02:00:03.213101 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0805 02:00:03.213943 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0805 02:00:04.841096 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0805 02:00:04.905900 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0805 02:00:13.701801 140709607630592 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0805 02:00:13.745492 140709607630592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0805 02:00:13.888211 140709607630592 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46284 samples, validate on 11571 samples\n",
      "Epoch 1/25\n",
      "46284/46284 [==============================] - 223s 5ms/step - loss: 0.5572 - acc: 0.7609 - val_loss: 0.2744 - val_acc: 0.9118\n",
      "Epoch 2/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.1518 - acc: 0.9420 - val_loss: 0.2606 - val_acc: 0.9264\n",
      "Epoch 3/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0542 - acc: 0.9819 - val_loss: 0.3224 - val_acc: 0.9475\n",
      "Epoch 4/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0320 - acc: 0.9893 - val_loss: 0.3829 - val_acc: 0.9183\n",
      "Epoch 5/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0280 - acc: 0.9906 - val_loss: 0.3981 - val_acc: 0.8955\n",
      "Epoch 6/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0237 - acc: 0.9923 - val_loss: 0.4275 - val_acc: 0.9414\n",
      "Epoch 7/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0196 - acc: 0.9932 - val_loss: 0.4643 - val_acc: 0.9033\n",
      "Epoch 8/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0242 - acc: 0.9922 - val_loss: 0.4812 - val_acc: 0.8947\n",
      "Epoch 9/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.4102 - val_acc: 0.9267\n",
      "Epoch 10/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.4812 - val_acc: 0.8984\n",
      "Epoch 11/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.6704 - val_acc: 0.8489\n",
      "Epoch 12/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.4504 - val_acc: 0.9042\n",
      "Epoch 13/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.4694 - val_acc: 0.9394\n",
      "Epoch 14/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0119 - acc: 0.9957 - val_loss: 0.5303 - val_acc: 0.9059\n",
      "Epoch 15/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.4538 - val_acc: 0.9298\n",
      "Epoch 16/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.4324 - val_acc: 0.9254\n",
      "Epoch 17/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.7144 - val_acc: 0.8636\n",
      "Epoch 18/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.6405 - val_acc: 0.8663\n",
      "Epoch 19/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.5140 - val_acc: 0.9003\n",
      "Epoch 20/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.4707 - val_acc: 0.9327\n",
      "Epoch 21/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.4343 - val_acc: 0.9082\n",
      "Epoch 22/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.7296 - val_acc: 0.8684\n",
      "Epoch 23/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.7014 - val_acc: 0.8749\n",
      "Epoch 24/25\n",
      "46284/46284 [==============================] - 206s 4ms/step - loss: 0.0062 - acc: 0.9978 - val_loss: 0.5322 - val_acc: 0.9093\n",
      "Epoch 25/25\n",
      "46284/46284 [==============================] - 205s 4ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.4833 - val_acc: 0.9221\n"
     ]
    }
   ],
   "source": [
    "#train first split\n",
    "base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (128,128,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model_dssm1 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_dssm1.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history1 = model_dssm1.fit(X_sm, Y_sm, validation_data=(testX, testY), epochs= 25, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922133\n",
      "Precision: 0.380151\n",
      "Recall: 0.379247\n",
      "F1 score: 0.366522\n",
      "Confusion Matrix:\n",
      " [[10542   332   122     5]\n",
      " [  272    81    46     0]\n",
      " [   70    29    46     0]\n",
      " [    9     6    10     1]]\n"
     ]
    }
   ],
   "source": [
    "#model predictions\n",
    "predictions = model_dssm1.predict(testX)\n",
    "predY = np.argmax(predictions, axis=1)\n",
    "testY = np.argmax(testY, axis=1)\n",
    "#Results #1\n",
    "eval(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Road Accidents - Second Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46283, 128, 128, 3) (46283,) (11571, 128, 128, 3) (11571,)\n",
      "Counter({0: 43973, 1: 1620, 2: 582, 3: 108}) Counter({0: 10964, 1: 429, 2: 150, 3: 28})\n",
      "Mean:  11571\n",
      "After SMOTE:  (78686, 49152) (78686,) Counter({0: 43973, 1: 11571, 2: 11571, 3: 11571})\n",
      "After undersampling Majority:  (34713, 49152) (34713,) (43973, 49152)\n",
      "Final Class Counter:  Counter({0: 11571, 1: 11571, 2: 11571, 3: 11571})\n",
      "Final training dataset:  (46284, 128, 128, 3) (46284, 4)\n",
      "Final validation dataset:  (11571, 128, 128, 3) (11571, 4)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainX, trainY, testX, testY = load_saved_dataset('total_acc.npz')\n",
    "print(Counter(trainY), Counter(testY))\n",
    "#find average number of instances\n",
    "m = round(sum(Counter(trainY).values())/4)\n",
    "print('Mean: ', m)\n",
    "#implement SMOTE on minority classes\n",
    "trainX = trainX.reshape(trainX.shape[0], -1)\n",
    "sm = SMOTE({1:m, 2:m, 3:m})\n",
    "X_sm, Y_sm = sm.fit_sample(trainX, trainY)\n",
    "print('After SMOTE: ', X_sm.shape, Y_sm.shape, Counter(Y_sm))\n",
    "#split out majority set from dataset\n",
    "ds_maj = []\n",
    "X_tmp = []\n",
    "Y_tmp = []\n",
    "for i in range(len(X_sm)):\n",
    "    target = Y_sm[i]\n",
    "    var = X_sm[i]\n",
    "    if target == 0:\n",
    "        ds_maj.append(var)\n",
    "    if target == 1:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(1)\n",
    "    if target == 2:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(2)\n",
    "    if target == 3:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(3)\n",
    "\n",
    "X_tmp = np.asarray(X_tmp)\n",
    "Y_tmp = np.asarray(Y_tmp)\n",
    "ds_maj = np.asarray(ds_maj)\n",
    "print('After undersampling Majority: ', X_tmp.shape, Y_tmp.shape, ds_maj.shape)\n",
    "#undersample majority set to m number of instances\n",
    "ds_maj = shuffle(ds_maj, n_samples=m)\n",
    "#generate target set of 0's for undersampled majority set\n",
    "ds_maj_y = np.repeat(0, len(ds_maj))\n",
    "#combine datasets\n",
    "X1_tmp = np.concatenate([X_tmp, ds_maj])\n",
    "Y1_tmp = np.concatenate([Y_tmp, ds_maj_y])\n",
    "#shuffle combined dataset\n",
    "X_sm, Y_sm = shuffle(X1_tmp, Y1_tmp, random_state=1)\n",
    "print('Final Class Counter: ', Counter(Y_sm))\n",
    "#prepare data for training\n",
    "X_sm = X_sm.reshape(X_sm.shape[0], 128, 128, 3)\n",
    "Y_sm = to_categorical(Y_sm)\n",
    "testY = to_categorical(testY)\n",
    "print('Final training dataset: ', X_sm.shape, Y_sm.shape)\n",
    "print('Final validation dataset: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 03:34:47.951003 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0805 03:34:47.967174 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 03:34:47.973263 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0805 03:34:47.998947 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0805 03:34:47.999760 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0805 03:34:49.578499 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0805 03:34:49.646071 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0805 03:34:58.293322 139935769405184 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0805 03:34:58.335288 139935769405184 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0805 03:34:58.467813 139935769405184 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46284 samples, validate on 11571 samples\n",
      "Epoch 1/25\n",
      "46284/46284 [==============================] - 223s 5ms/step - loss: 0.5458 - acc: 0.7692 - val_loss: 0.2748 - val_acc: 0.9152\n",
      "Epoch 2/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.1518 - acc: 0.9440 - val_loss: 0.2842 - val_acc: 0.9030\n",
      "Epoch 3/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0502 - acc: 0.9830 - val_loss: 0.2906 - val_acc: 0.9240\n",
      "Epoch 4/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.3301 - val_acc: 0.9243\n",
      "Epoch 5/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0245 - acc: 0.9914 - val_loss: 0.3965 - val_acc: 0.9067\n",
      "Epoch 6/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0248 - acc: 0.9916 - val_loss: 0.4218 - val_acc: 0.9054\n",
      "Epoch 7/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.5888 - val_acc: 0.8697\n",
      "Epoch 8/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0171 - acc: 0.9942 - val_loss: 0.4320 - val_acc: 0.9185\n",
      "Epoch 9/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.5511 - val_acc: 0.8904\n",
      "Epoch 10/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.4570 - val_acc: 0.9163\n",
      "Epoch 11/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.4372 - val_acc: 0.9247\n",
      "Epoch 12/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0115 - acc: 0.9963 - val_loss: 0.5387 - val_acc: 0.9055\n",
      "Epoch 13/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.4032 - val_acc: 0.9282\n",
      "Epoch 14/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.4793 - val_acc: 0.9181\n",
      "Epoch 15/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.5494 - val_acc: 0.9046\n",
      "Epoch 16/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0115 - acc: 0.9963 - val_loss: 0.4344 - val_acc: 0.9289\n",
      "Epoch 17/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.7388 - val_acc: 0.8571\n",
      "Epoch 18/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.4354 - val_acc: 0.9284\n",
      "Epoch 19/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.4691 - val_acc: 0.9223\n",
      "Epoch 20/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.4830 - val_acc: 0.9236\n",
      "Epoch 21/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.5062 - val_acc: 0.9380\n",
      "Epoch 22/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.6048 - val_acc: 0.8919\n",
      "Epoch 23/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.5424 - val_acc: 0.9033\n",
      "Epoch 24/25\n",
      "46284/46284 [==============================] - 203s 4ms/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.5196 - val_acc: 0.9356\n",
      "Epoch 25/25\n",
      "46284/46284 [==============================] - 204s 4ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.5526 - val_acc: 0.9220\n"
     ]
    }
   ],
   "source": [
    "#train second split\n",
    "base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (128,128,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model_dssm2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_dssm2.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history2 = model_dssm2.fit(X_sm, Y_sm, validation_data=(testX, testY), epochs= 25, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922046\n",
      "Precision: 0.405605\n",
      "Recall: 0.344827\n",
      "F1 score: 0.353959\n",
      "Confusion Matrix:\n",
      " [[10549   356    59     0]\n",
      " [  307    95    24     3]\n",
      " [   98    28    24     0]\n",
      " [   18     4     5     1]]\n"
     ]
    }
   ],
   "source": [
    "#model predictions\n",
    "predictions = model_dssm2.predict(testX)\n",
    "predY = np.argmax(predictions, axis=1)\n",
    "testY = np.argmax(testY, axis=1)\n",
    "#Results #2\n",
    "eval(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Road Accidents - Third Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46283, 128, 128, 3) (46283,) (11571, 128, 128, 3) (11571,)\n",
      "Counter({0: 43941, 1: 1634, 2: 601, 3: 107}) Counter({0: 10996, 1: 415, 2: 131, 3: 29})\n",
      "Mean:  11571\n",
      "After SMOTE:  (78654, 49152) (78654,) Counter({0: 43941, 1: 11571, 2: 11571, 3: 11571})\n",
      "After undersampling Majority:  (34713, 49152) (34713,) (43941, 49152)\n",
      "Final Class Counter:  Counter({0: 11571, 1: 11571, 2: 11571, 3: 11571})\n",
      "Final training dataset:  (46284, 128, 128, 3) (46284, 4)\n",
      "Final validation dataset:  (11571, 128, 128, 3) (11571, 4)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainX, trainY, testX, testY = load_saved_dataset('total_acc.npz')\n",
    "print(Counter(trainY), Counter(testY))\n",
    "#find average number of instances\n",
    "m = round(sum(Counter(trainY).values())/4)\n",
    "print('Mean: ', m)\n",
    "#implement SMOTE on minority classes\n",
    "trainX = trainX.reshape(trainX.shape[0], -1)\n",
    "sm = SMOTE({1:m, 2:m, 3:m})\n",
    "X_sm, Y_sm = sm.fit_sample(trainX, trainY)\n",
    "print('After SMOTE: ', X_sm.shape, Y_sm.shape, Counter(Y_sm))\n",
    "#split out majority set from dataset\n",
    "ds_maj = []\n",
    "X_tmp = []\n",
    "Y_tmp = []\n",
    "for i in range(len(X_sm)):\n",
    "    target = Y_sm[i]\n",
    "    var = X_sm[i]\n",
    "    if target == 0:\n",
    "        ds_maj.append(var)\n",
    "    if target == 1:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(1)\n",
    "    if target == 2:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(2)\n",
    "    if target == 3:\n",
    "        X_tmp.append(var)\n",
    "        Y_tmp.append(3)\n",
    "\n",
    "X_tmp = np.asarray(X_tmp)\n",
    "Y_tmp = np.asarray(Y_tmp)\n",
    "ds_maj = np.asarray(ds_maj)\n",
    "print('After undersampling Majority: ', X_tmp.shape, Y_tmp.shape, ds_maj.shape)\n",
    "#undersample majority set to m number of instances\n",
    "ds_maj = shuffle(ds_maj, n_samples=m)\n",
    "#generate target set of 0's for undersampled majority set\n",
    "ds_maj_y = np.repeat(0, len(ds_maj))\n",
    "#combine datasets\n",
    "X1_tmp = np.concatenate([X_tmp, ds_maj])\n",
    "Y1_tmp = np.concatenate([Y_tmp, ds_maj_y])\n",
    "#shuffle combined dataset\n",
    "X_sm, Y_sm = shuffle(X1_tmp, Y1_tmp, random_state=1)\n",
    "print('Final Class Counter: ', Counter(Y_sm))\n",
    "#prepare data for training\n",
    "X_sm = X_sm.reshape(X_sm.shape[0], 128, 128, 3)\n",
    "Y_sm = to_categorical(Y_sm)\n",
    "testY = to_categorical(testY)\n",
    "print('Final training dataset: ', X_sm.shape, Y_sm.shape)\n",
    "print('Final validation dataset: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 04:09:38.751120 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 04:09:38.770299 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 04:09:38.776309 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0804 04:09:38.800039 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0804 04:09:38.800818 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 04:09:40.432538 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0804 04:09:40.499406 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0804 04:09:49.272983 140070680270592 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 04:09:49.318124 140070680270592 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 04:09:49.452824 140070680270592 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46284 samples, validate on 11571 samples\n",
      "Epoch 1/25\n",
      "46284/46284 [==============================] - 234s 5ms/step - loss: 0.5583 - acc: 0.7652 - val_loss: 0.2164 - val_acc: 0.9365\n",
      "Epoch 2/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.1496 - acc: 0.9443 - val_loss: 0.2315 - val_acc: 0.9283\n",
      "Epoch 3/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0523 - acc: 0.9827 - val_loss: 0.3757 - val_acc: 0.9008\n",
      "Epoch 4/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0324 - acc: 0.9891 - val_loss: 0.4618 - val_acc: 0.8870\n",
      "Epoch 5/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0270 - acc: 0.9909 - val_loss: 0.5224 - val_acc: 0.8671\n",
      "Epoch 6/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.5508 - val_acc: 0.8924\n",
      "Epoch 7/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0226 - acc: 0.9924 - val_loss: 0.4014 - val_acc: 0.9092\n",
      "Epoch 8/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.4456 - val_acc: 0.9051\n",
      "Epoch 9/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.4547 - val_acc: 0.9093\n",
      "Epoch 10/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.5309 - val_acc: 0.8986\n",
      "Epoch 11/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0093 - acc: 0.9967 - val_loss: 0.4106 - val_acc: 0.9256\n",
      "Epoch 12/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0175 - acc: 0.9943 - val_loss: 0.3799 - val_acc: 0.9318\n",
      "Epoch 13/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0124 - acc: 0.9955 - val_loss: 0.5605 - val_acc: 0.8920\n",
      "Epoch 14/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.7385 - val_acc: 0.8539\n",
      "Epoch 15/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.4715 - val_acc: 0.9043\n",
      "Epoch 16/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.4476 - val_acc: 0.9324\n",
      "Epoch 17/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0074 - acc: 0.9973 - val_loss: 0.4483 - val_acc: 0.9213\n",
      "Epoch 18/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.8654 - val_acc: 0.8419\n",
      "Epoch 19/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.4709 - val_acc: 0.9253\n",
      "Epoch 20/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.5766 - val_acc: 0.9038\n",
      "Epoch 21/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.5141 - val_acc: 0.9233\n",
      "Epoch 22/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.5900 - val_acc: 0.9121\n",
      "Epoch 23/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0100 - acc: 0.9972 - val_loss: 0.7644 - val_acc: 0.8757\n",
      "Epoch 24/25\n",
      "46284/46284 [==============================] - 211s 5ms/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.7583 - val_acc: 0.8780\n",
      "Epoch 25/25\n",
      "46284/46284 [==============================] - 212s 5ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.5211 - val_acc: 0.9103\n"
     ]
    }
   ],
   "source": [
    "#train third split\n",
    "base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (128,128,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model_dssm3 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_dssm3.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history3 = model_dssm3.fit(X_sm, Y_sm, validation_data=(testX, testY), epochs= 25, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910293\n",
      "Precision: 0.436648\n",
      "Recall: 0.359432\n",
      "F1 score: 0.354095\n",
      "Confusion Matrix:\n",
      " [[10374   596    25     1]\n",
      " [  257   148     9     1]\n",
      " [   67    54     9     1]\n",
      " [    9    15     3     2]]\n"
     ]
    }
   ],
   "source": [
    "#model predictions\n",
    "predictions = model_dssm3.predict(testX)\n",
    "predY = np.argmax(predictions, axis=1)\n",
    "testY = np.argmax(testY, axis=1)\n",
    "#Results #3\n",
    "eval(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
